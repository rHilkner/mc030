{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC030 - Projeto final de Graduação\n",
    "## Análise e Previsão do Mercado de Ações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição do modelo\n",
    "\n",
    "A partir de um conjunto de cotações diárias de dólar para real (USD-BRL) desejamos modelar esse comportamento a partir de uma série de indicadores de mercado financeiro para classificarmos cada dia como um momento de compra ou momento de venda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo endpoints da API (https://www.alphavantage.co/documentation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiToken = '3GX5M109KQK9B6HO'\n",
    "baseUrl = 'https://www.alphavantage.co/query?&outputsize=full&apikey=' + apiToken\n",
    "usdBrlUrl = 'https://www.alphavantage.co/query?function=FX_DAILY&from_symbol=USD&to_symbol=BRL&outputsize=full&apikey=' + apiToken\n",
    "stockUrl = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&outputsize=full&apikey=demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo dados da API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "callsMade = 0\n",
    "\n",
    "def incrementAndVerifyCallsMade():\n",
    "    global callsMade\n",
    "    if callsMade == 4:\n",
    "        print('Made 5 requests to the API in the last minute - sleeping for 1 minute')\n",
    "        time.sleep(65)\n",
    "        callsMade = 0\n",
    "    callsMade += 1\n",
    "    \n",
    "def parsePriceRetrieved(stocksRetrieved):\n",
    "    stockPrices = {}\n",
    "    for date, candle in stocksRetrieved.items():\n",
    "        stockPrices[date] = candle['1. open']\n",
    "    return stockPrices\n",
    "def parseIndicatorRetrieved(indicatorsRetrieved):\n",
    "    indicatorValues = {}\n",
    "    for date, indicator in indicatorsRetrieved.items():\n",
    "        for indicatorSymbol, indicatorValue in indicator.items():\n",
    "            if indicatorSymbol == 'Chaikin A/D':\n",
    "                indicatorSymbol = 'AD'\n",
    "            elif indicatorSymbol == 'MACD_Signal' or indicatorSymbol == 'MACD_Hist':\n",
    "                continue\n",
    "            indicatorValues[date] = {indicatorSymbol: indicatorValue}\n",
    "    return indicatorValues\n",
    "# returns [{date: price}]\n",
    "def getStockPrice(stockSymbol):\n",
    "    stockUrl = baseUrl + '&function=TIME_SERIES_DAILY&symbol=' + stockSymbol\n",
    "    print('Fetching ' + stockUrl)\n",
    "    incrementAndVerifyCallsMade()\n",
    "    stocksRetrieved = requests.get(stockUrl).json();\n",
    "    stocks = parsePriceRetrieved(stocksRetrieved['Time Series (Daily)'])\n",
    "    print('Retrieved and parsed '+ stockSymbol)\n",
    "    return stocks\n",
    "# returns [{date: price}]\n",
    "def getForexPrice(fromSymbol, toSymbol):\n",
    "    forexUrl = baseUrl + '&function=FX_DAILY&from_symbol=' + fromSymbol + '&to_symbol=' + toSymbol\n",
    "    print('Fetching ' + forexUrl)\n",
    "    incrementAndVerifyCallsMade()\n",
    "    forexRetrieved = requests.get(forexUrl).json();\n",
    "    forex = parsePriceRetrieved(forexRetrieved)\n",
    "    print('Retrieved and parsed '+ fromSymbol + toSymbol)\n",
    "    return forex\n",
    "# returns [date: [{indicatorFunction: indicatorValue}]]\n",
    "def getIndicator(indicatorFunction, symbol):\n",
    "    indicatorUrl = baseUrl + '&interval=daily&series_type=open&function=' + indicatorFunction + '&symbol=' + symbol\n",
    "    if indicatorFunction=='SMA':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='EMA':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='WMA':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='DEMA':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='TEMA':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='TRIMA':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='KAMA':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='MAMA':\n",
    "        indicatorUrl += '&fastlimit=0.01&slowlimit=0.01'\n",
    "    elif indicatorFunction=='T3':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='MACD':\n",
    "        indicatorUrl += '&fastperiod=12&slowperiod=26&signalperiod=9'\n",
    "    elif indicatorFunction=='MACDEXT':\n",
    "        indicatorUrl += '&fastperiod=12&slowperiod=26&signalperiod=9&fastmatype=0&slowmatype=0&signalmatype=0'\n",
    "    elif indicatorFunction=='STOCH':\n",
    "        indicatorUrl += '&fastkperiod=5&slowkperiod=3&slowdperiod=3&slowkmatype=0&slowdmatype=0'\n",
    "    elif indicatorFunction=='STOCHF':\n",
    "        indicatorUrl += '&fastkperiod=5&fastdperiod=3&fastdmatype=0'\n",
    "    elif indicatorFunction=='RSI':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='STOCHRSI':\n",
    "        indicatorUrl += '&time_period=10&fastkperiod=5&fastdperiod=3&fastdmatype=0'\n",
    "    elif indicatorFunction=='WILLR':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='ADX':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='ADXR':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='APO':\n",
    "        indicatorUrl += '&fastperiod=12&slowperiod=26&matype=0'\n",
    "    elif indicatorFunction=='PPO':\n",
    "        indicatorUrl += '&fastperiod=12&slowperiod=26&matype=0'\n",
    "    elif indicatorFunction=='MOM':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='BOP':\n",
    "        indicatorUrl += ''\n",
    "    elif indicatorFunction=='CCI':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='CMO':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='CCI':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='ROC':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='ROCR':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='AROON':\n",
    "        indicatorUrl += '&time_period=14'\n",
    "    elif indicatorFunction=='AROONOSC':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='MFI':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='TRIX':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='ULTOSC':\n",
    "        indicatorUrl += '&timeperiod1=7&timeperiod2=14&timeperiod3=28'\n",
    "    elif indicatorFunction=='DX':\n",
    "        indicatorUrl += '&time_period=10'\n",
    "    elif indicatorFunction=='AD':\n",
    "        indicatorUrl += ''\n",
    "        indicatorFunction = 'Chaikin A/D'\n",
    "    elif indicatorFunction=='OBV':\n",
    "        indicatorUrl += ''\n",
    "    # TODO: terminar isso aqi\n",
    "    print('Fetching ' + indicatorUrl)\n",
    "    incrementAndVerifyCallsMade();\n",
    "    indicatorRetrieved = requests.get(indicatorUrl).json()\n",
    "    indicators = parseIndicatorRetrieved(indicatorRetrieved['Technical Analysis: ' + indicatorFunction])\n",
    "    print('Retrieved and parsed '+ indicatorFunction)\n",
    "    return indicators\n",
    "# returns [date: [{indicatorFunction: indicatorValue}]]\n",
    "def getIndicatorList(indicatorFunctions, symbol):\n",
    "    indicators = {}\n",
    "    for indicatorFunction in indicatorFunctions:\n",
    "        indicatorDict = getIndicator(indicatorFunction, symbol)\n",
    "        for date, indicator in indicatorDict.items():\n",
    "            for indicatorFunction, indicatorValue in indicator.items():\n",
    "                if  date not in indicators:\n",
    "                    indicators[date] = {}\n",
    "                indicators[date][indicatorFunction] = indicatorValue\n",
    "    return indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando dados válidos - apenas aqueles cujas datas estão na lista de preços e de indicadores\n",
    "def filterData(prices, indicators, indicatorFunctions):\n",
    "    filteredPrices = {date: price for date, price in prices.items() if date in indicators.keys()}\n",
    "    filteredIndicators = {date: indicators for date, indicators in indicators.items() if date in prices.keys()}\n",
    "    return filteredPrices, filteredIndicators\n",
    "\n",
    "def getData(stockSymbol, indicatorFunctions):\n",
    "    stockPrices = getStockPrice(stockSymbol)\n",
    "    indicators = getIndicatorList(indicatorFunctions, stockSymbol)\n",
    "    stockPrices, indicators = filterData(stockPrices, indicators, indicatorFunctions)\n",
    "    return stockPrices, indicators\n",
    "\n",
    "def getForexData(fromForexSymbol, toForexSymbol, indicatorFunctions):\n",
    "    forexPrices = getForexPrice(fromForexSymbol, toForexSymbol)\n",
    "    indicators = getIndicatorList(indicatorFunctions, fromForexSymbol + toForexSymbol)\n",
    "    forexPrices, indicators = filterData(forexPrices, indicators)\n",
    "    return forexPrices, indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de anotação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def annotateBuyOrSellTwoClasses(prices):\n",
    "    dateAnnotated = {}\n",
    "    yesterdayDate = ''\n",
    "    earlierDate = ''\n",
    "    last = ''\n",
    "    for key, value in prices.items():\n",
    "        yesterdayDate = key\n",
    "        yesterdayPrice = float(value)\n",
    "        break\n",
    "    for date, price in prices.items():\n",
    "        if float(price) > yesterdayPrice:\n",
    "            dateAnnotated[yesterdayDate] = 'B'\n",
    "            last = 'B'\n",
    "        elif float(price) < yesterdayPrice:\n",
    "            dateAnnotated[yesterdayDate] = 'S'\n",
    "            last = 'S'\n",
    "        else:\n",
    "            dateAnnotated[yesterdayDate] = last\n",
    "        yesterdayDate = date\n",
    "        yesterdayPrice = float(price)\n",
    "    return dateAnnotated\n",
    "\n",
    "def annotateBuyOrSellEightClasses(prices):\n",
    "    dateAnnotated = {}\n",
    "    yesterdayDate = ''\n",
    "    earlierDate = ''\n",
    "    last = ''\n",
    "    for key, value in prices.items():\n",
    "        yesterdayDate = key\n",
    "        yesterdayPrice = float(value)\n",
    "        break\n",
    "    for date, price in prices.items():\n",
    "        if float(price) > yesterdayPrice and float(price)/yesterdayPrice <= 1.005:\n",
    "            dateAnnotated[yesterdayDate] = 'B0'\n",
    "            last = 'B0'\n",
    "        elif float(price) > yesterdayPrice and float(price)/yesterdayPrice <= 1.01:\n",
    "            dateAnnotated[yesterdayDate] = 'B1'\n",
    "            last = 'B1'\n",
    "        elif float(price) > yesterdayPrice and float(price)/yesterdayPrice <= 1.02:\n",
    "            dateAnnotated[yesterdayDate] = 'B2'\n",
    "            last = 'B2'\n",
    "        elif float(price) > yesterdayPrice and float(price)/yesterdayPrice > 1.02:\n",
    "            dateAnnotated[yesterdayDate] = 'B3'\n",
    "            last = 'B3'\n",
    "        elif float(price) < yesterdayPrice and float(price)/yesterdayPrice >= .995:\n",
    "            dateAnnotated[yesterdayDate] = 'S0'\n",
    "            last = 'S0'\n",
    "        elif float(price) < yesterdayPrice and float(price)/yesterdayPrice >= .99:\n",
    "            dateAnnotated[yesterdayDate] = 'S1'\n",
    "            last = 'S1'\n",
    "        elif float(price) < yesterdayPrice and float(price)/yesterdayPrice >= .98:\n",
    "            dateAnnotated[yesterdayDate] = 'S2'\n",
    "            last = 'S2'\n",
    "        elif float(price) < yesterdayPrice and float(price)/yesterdayPrice < .98:\n",
    "            dateAnnotated[yesterdayDate] = 'S3'\n",
    "            last = 'S3'\n",
    "        else:\n",
    "            dateAnnotated[yesterdayDate] = last\n",
    "        yesterdayDate = date\n",
    "        yesterdayPrice = float(price)\n",
    "    return dateAnnotated\n",
    "\n",
    "def annotateMaxProfit(prices):\n",
    "    dateAnnotated = {}\n",
    "    yesterdayDate = ''\n",
    "    yesterdayPrice = 0\n",
    "    currentStatus = ''\n",
    "    for key, value in prices.items():\n",
    "        yesterdayDate = key\n",
    "        yesterdayPrice = value\n",
    "        break\n",
    "    for date, price in prices.items():\n",
    "        if price > yesterdayPrice and currentStatus != 'B':\n",
    "            dateAnnotated[yesterdayDate] = 'B'\n",
    "            currentStatus = 'B'\n",
    "        elif price < yesterdayPrice and currentStatus != 'S':\n",
    "            dateAnnotated[yesterdayDate] = 'S'\n",
    "            currentStatus = 'S'\n",
    "        yesterdayDate = date\n",
    "        yesterdayPrice = price\n",
    "    return dateAnnotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dúvida - como faremos a normalização?\n",
    "# Ideia: normalizarmos de acordo com o preço da ação no momento\n",
    "\n",
    "# Exemplo: temos o valor de uma ação atualmente em R$3.00, mas sua média dos últimos 10 dias é de R$2.90,\n",
    "# logo esta ação está aumentando de valor. Se normalizarmos todos os indicadores de acordo com o preço atual\n",
    "# da ação podemos ter mais sucesso, pois no momento de atuação do modelo tudo que ele terá acesso será o preço \n",
    "# atual da ação e seus indicadores... Normalizar de acordo com um teto e piso de valores acho que pode dar ruim.\n",
    "\n",
    "import copy\n",
    "\n",
    "# Normaliza um conjunto de indicadores a partir do preço da ação\n",
    "def normalizeIndicators(indicatorSet, stockPrice):\n",
    "    normalizedIndicatorSet = {}\n",
    "    for indicatorFunction, indicatorValue in indicatorSet.items():\n",
    "        normalizedIndicatorSet[indicatorFunction] = float(indicatorValue)/float(stockPrice)\n",
    "    return normalizedIndicatorSet\n",
    "\n",
    "# Retorna os indicadores normalizados: indicadores = [date: {indicators: ['SMA': 0.89, 'EMA': 0.93], annotation: 'B'}]\n",
    "def getIndicatorsNormalizedAndAnnotaded(stockPrices, indicators, dateAnnotated):\n",
    "    print('Normalizing and annotating indicators')\n",
    "    indicatorsAnnotated = {}\n",
    "    for date, annotation in dateAnnotated.items():\n",
    "        if date not in indicatorsAnnotated:\n",
    "            indicatorsAnnotated[date] = {'indicators': {}, 'annotation': ''}\n",
    "        indicatorsAnnotated[date]['indicators'] = normalizeIndicators(indicators[date], stockPrices[date])\n",
    "        indicatorsAnnotated[date]['annotation'] = annotation\n",
    "    return indicatorsAnnotated\n",
    "\n",
    "# Deprecated\n",
    "def normalizeIndicatorsOld(indicatorsAnnotated):\n",
    "    normalizedIndicators = {'B': [], 'S': []}\n",
    "    for indicatorSet in indicatorsAnnotated['B']:\n",
    "        normalizedIndicatorSet = []\n",
    "        for indicator, value in indicatorSet.items():\n",
    "            print(indicator)\n",
    "            normalizedIndicatorSet.append({indicator: value/1000})\n",
    "        normalizedIndicators[B].append(normalizedIndicatorSet)\n",
    "    for indicators in indicatorsAnnotated['S']:\n",
    "        print(indicators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ec5b45b849ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetModelMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "def getModelMLP(n_steps, n_features, n_outputs):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(64, activation='relu', input_shape=(n_steps*n_features,)))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    if (n_outputs > 1):\n",
    "        activation = 'softmax'\n",
    "        loss = 'categorical_crossentropy'\n",
    "    else:\n",
    "        activation = 'sigmoid'\n",
    "        loss = 'binary_crossentropy'\n",
    "    model.add(keras.layers.Dense(n_outputs, activation=activation))\n",
    "    model.compile(loss=loss, optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def getModelBidirectionalLSTM(n_steps, n_features, n_outputs):    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(64, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "    if (n_outputs > 1):\n",
    "        activation = 'softmax'\n",
    "        loss = 'categorical_crossentropy'\n",
    "    else:\n",
    "        activation = 'sigmoid'\n",
    "        loss = 'binary_crossentropy'\n",
    "    model.add(keras.layers.Dense(n_outputs, activation=activation))\n",
    "    model.compile(loss=loss, optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def getModelCNN(n_steps, n_features):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "    model.add(keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    if (n_outputs > 1):\n",
    "        activation = 'softmax'\n",
    "        loss = 'categorical_crossentropy'\n",
    "    else:\n",
    "        activation = 'sigmoid'\n",
    "        loss = 'binary_crossentropy'\n",
    "    model.add(keras.layers.Dense(n_outputs, activation=activation))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheat-sheet com os simbolos\n",
    "__indicatorSymbols = ['SMA', 'EMA', 'WMA', 'DEMA', 'TEMA', 'TRIMA', 'KAMA', 'MAMA',\n",
    "                      'T3', 'MACD', 'MACDEXT', 'STOCH', 'STOCHF', 'RSI', 'STOCHRSI', 'WILLR', \n",
    "                      'ADX', 'ADXR', 'APO', 'PPO', 'MOM', 'BOP', 'CCI', 'CMO', 'ROC', 'ROCR',\n",
    "                      'AROON', 'AROONOSC', 'MFI', 'TRIX', 'ULTOSC', 'DX', 'MINUS_DI', 'PLUS_DI',\n",
    "                      'MINUS_DM', 'PLUS_DM', 'BBANDS', 'MIDPOINT', 'SAR', 'TRANGE', 'ATR',\n",
    "                      'NATR', 'AD', 'ADOSC', 'OBV', 'HT_TRENDLINE', 'HT_SINE', 'HT_TRENDMODE',\n",
    "                      'HT_DCPERIOD', 'HT_DCPHASE', 'HT_PHASOR']\n",
    "__forexSymbols = ['BRL', 'EUR']\n",
    "__stockSymbols = ['MSFT']\n",
    "\n",
    "# Definindo simbolos para o modelo\n",
    "indicatorFunctions = ['SMA', 'EMA', 'WMA']\n",
    "indicatorFunctions2 = ['SMA', 'EMA', 'MACD', 'RSI', 'ADX', 'CCI', 'AD', 'OBV']\n",
    "indicatorFunctions3 = ['SMA', 'EMA', 'MACD', 'RSI', 'ADX', 'CCI', 'AD', 'OBV', 'MOM', 'WILLR', 'ADOSC']\n",
    "# fromForexSymbol = 'USD'\n",
    "# toForexSymbol = 'BRL'\n",
    "stockSymbol = 'MSFT'\n",
    "\n",
    "stockPrices, indicators = getData(stockSymbol, indicatorFunctions)\n",
    "# stockPrices, indicators2 = getData(stockSymbol, indicatorFunctions2)\n",
    "# stockPrices, indicators3 = getData(stockSymbol, indicatorFunctions3)\n",
    "# forexPrices, indicators = getForexData(fromForexSymbol, toForexSymbol, indicatorFunctions)\n",
    "# dateAnnotated = annotateMaxProfit(stockPrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(stockPrices, orient='index')\n",
    "\n",
    "div = df[0].astype('float').div(df[0].astype('float').shift(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(inplace=True)\n",
    "df[0].astype('float').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div.sort_index(inplace=True)\n",
    "div.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "div.describe(percentiles=[.01,.1,.25,.5,.75,.9,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateAnnotatedTwo = annotateBuyOrSellTwoClasses(stockPrices)\n",
    "df = pd.DataFrame.from_dict(dateAnnotatedTwo, orient='index')\n",
    "df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateAnnotatedEight = annotateBuyOrSellEightClasses(stockPrices)\n",
    "df = pd.DataFrame.from_dict(dateAnnotatedEight, orient='index')\n",
    "df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedIndicatorsTwo = getIndicatorsNormalizedAndAnnotaded(stockPrices, indicators, dateAnnotatedTwo)\n",
    "normalizedIndicatorsEight = getIndicatorsNormalizedAndAnnotaded(stockPrices, indicators, dateAnnotatedEight)\n",
    "\n",
    "dataTwo = pd.DataFrame.from_dict(normalizedIndicatorsTwo, orient='index')\n",
    "dataEight = pd.DataFrame.from_dict(normalizedIndicatorsEight, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTwo = pd.DataFrame.merge(pd.DataFrame(dataTwo.indicators.values.tolist(), index=dataTwo.index), dataTwo, left_index=True, right_index=True, how='outer').drop(columns=['indicators'])\n",
    "dataEight = pd.DataFrame.merge(pd.DataFrame(dataEight.indicators.values.tolist(), index=dataEight.index), dataEight, left_index=True, right_index=True, how='outer').drop(columns=['indicators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTwo.head(), dataEight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTwo.annotation = dataTwo.annotation.apply(lambda x: 0 if x == 'S' else 1)\n",
    "\n",
    "eight_dict = {\"B3\":0, \"B2\": 1, \"B1\": 2, \"B0\": 3, \"S0\": 4, \"S1\": 5, \"S2\": 6, \"S3\": 7}\n",
    "dataEight.annotation = dataEight.annotation.apply(lambda x: eight_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTwo = dataTwo.sort_index()\n",
    "dataEight = dataEight.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_steps = 4\n",
    "n_indicators = 3\n",
    "\n",
    "batch_size = 32\n",
    "train_split = .8\n",
    "\n",
    "X = {\n",
    "    \"mlp\": {\n",
    "        2 : [],\n",
    "        8 : [] \n",
    "    },\n",
    "    \"lstm\": {\n",
    "        2 : [],\n",
    "        8 : []\n",
    "    }\n",
    "}\n",
    "y = {\n",
    "    2 : [],\n",
    "    8 : [] \n",
    "}\n",
    "\n",
    "for i in range(len(dataTwo)):\n",
    "    end_ix = i + n_steps\n",
    "    if end_ix > len(dataTwo):\n",
    "        break\n",
    "    seq_x, seq_y = dataTwo.iloc[i:end_ix, :-1].values, dataTwo.iloc[end_ix-1, -1]\n",
    "    X[\"lstm\"][2].append(seq_x)\n",
    "    X[\"mlp\"][2].append(seq_x.flatten())\n",
    "    y[2].append(seq_y)\n",
    "    \n",
    "for i in range(len(dataEight)):\n",
    "    end_ix = i + n_steps\n",
    "    if end_ix > len(dataEight):\n",
    "        break\n",
    "    seq_x, seq_y = dataEight.iloc[i:end_ix, :-1].values, dataEight.iloc[end_ix-1, -1]\n",
    "    X[\"lstm\"][8].append(seq_x)\n",
    "    X[\"mlp\"][8].append(seq_x.flatten())\n",
    "    y[8].append(np.eye(8)[seq_y])\n",
    "\n",
    "X[\"lstm\"][2] = np.array(X[\"lstm\"][2])\n",
    "X[\"mlp\"][2] = np.array(X[\"mlp\"][2])\n",
    "y[2] = np.array(y[2])\n",
    "\n",
    "X[\"lstm\"][8] = np.array(X[\"lstm\"][8])\n",
    "X[\"mlp\"][8] = np.array(X[\"mlp\"][8])\n",
    "y[8] = np.array(y[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTwo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"lstm\"][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"mlp\"][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[\"lstm\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = {\n",
    "    \"mlp\": {\n",
    "    },\n",
    "    \"lstm\": {\n",
    "        2 : X[\"lstm\"][2][:int(len(X[\"lstm\"][2]) * train_split)],\n",
    "        8 : X[\"lstm\"][8][:int(len(X[\"lstm\"][8]) * train_split)]\n",
    "    }\n",
    "}\n",
    "\n",
    "X_test = {\n",
    "    \"mlp\": {\n",
    "    },\n",
    "    \"lstm\": {\n",
    "        2 : X[\"lstm\"][2][int(len(X[\"lstm\"][2]) * train_split):],\n",
    "        8 : X[\"lstm\"][8][int(len(X[\"lstm\"][8]) * train_split):]\n",
    "    }\n",
    "}\n",
    "\n",
    "y_train = {\n",
    "    \"mlp\": {\n",
    "    },\n",
    "    \"lstm\": {\n",
    "        2 : y[2][:int(len(y[2]) * train_split)],\n",
    "        8 : y[8][:int(len(y[8]) * train_split)] \n",
    "    }\n",
    "}\n",
    "\n",
    "y_test = {\n",
    "    \"mlp\": {\n",
    "    },\n",
    "    \"lstm\": {\n",
    "        2 : y[2][int(len(y[2]) * train_split):],\n",
    "        8 : y[8][int(len(y[2]) * train_split):] \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "X_train[\"mlp\"][2], X_test[\"mlp\"][2], y_train[\"mlp\"][2], y_test[\"mlp\"][2] = train_test_split(X[\"mlp\"][2], y[2], train_size=train_split, random_state=0)\n",
    "X_train[\"mlp\"][8], X_test[\"mlp\"][8], y_train[\"mlp\"][8], y_test[\"mlp\"][8] = train_test_split(X[\"mlp\"][8], y[8], train_size=train_split, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_2 = getModelMLP(n_steps, n_indicators, 1)\n",
    "MLP_8 = getModelMLP(n_steps, n_indicators, 8)\n",
    "\n",
    "LSTM_2 = getModelBidirectionalLSTM(n_steps, n_indicators, 1)\n",
    "LSTM_8 = getModelBidirectionalLSTM(n_steps, n_indicators, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_2, LSTM_2, MLP_8, LSTM_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {\n",
    "    \"mlp\": {2: [], 8:[]},\n",
    "    \"lstm\": {2: [], 8:[]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_mlp_2 = MLP_2.fit(X_train[\"mlp\"][2], y_train[\"mlp\"][2], epochs=300, verbose=1, validation_split=.2, batch_size=batch_size)\n",
    "plt.plot(history_mlp_2.history['loss'], label='train')\n",
    "plt.plot(history_mlp_2.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"mlp\"][2] = MLP_2.predict(X_test[\"mlp\"][2], batch_size=batch_size)\n",
    "print(classification_report(y_test[\"mlp\"][2], np.rint(preds[\"mlp\"][2]).astype(np.int64), target_names=[\"S\",\"B\"], digits=5))\n",
    "conf = plot_confusion_matrix(y_test[\"mlp\"][2], np.rint(preds[\"mlp\"][2]).astype(np.int64), classes=np.array([\"S\",\"B\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_8 = MLP_8.fit(X_train[\"mlp\"][8], y_train[\"mlp\"][8], epochs=300, verbose=1, validation_split=.2, batch_size=batch_size)\n",
    "plt.plot(history_mlp_8.history['loss'], label='train')\n",
    "plt.plot(history_mlp_8.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando lucro/prejuízo total, supondo que inicialmente temos US$1000 em carteira\n",
    "import copy\n",
    "\n",
    "classificationArray = list(np.argmax(preds[\"lstm\"][8], axis=1))\n",
    "\n",
    "prices = copy.deepcopy(stockPrices)\n",
    "\n",
    "for date in sorted(stockPrices.keys()):\n",
    "    if len(prices) == len(classificationArray):\n",
    "        break\n",
    "    del prices[date]\n",
    "\n",
    "initialMoney = 1000.00\n",
    "index = 0\n",
    "currentMoney = initialMoney\n",
    "currentStocks = 0.0\n",
    "\n",
    "for date in sorted(prices.keys()):\n",
    "    stockPrice = float(prices[date])\n",
    "    classification = classificationArray[index]\n",
    "    # Caso de compra\n",
    "    if currentMoney != 0 and (classification == 0 or classification == 1 or classification == 2 or classification == 3):\n",
    "        currentStocks = currentMoney/stockPrice\n",
    "        currentMoney = 0.0\n",
    "    elif currentStocks != 0 and (classification == 4 or classification == 5 or classification == 6 or classification == 7):\n",
    "        currentMoney = currentStocks*stockPrice\n",
    "        currentStocks = 0.0\n",
    "    index += 1\n",
    "\n",
    "firstPrice = float(prices[sorted(prices.keys())[0]])\n",
    "lastPrice = float(prices[sorted(prices.keys())[-1]])\n",
    "\n",
    "if currentMoney == 0:\n",
    "    finalMoney = currentStocks*lastPrice\n",
    "\n",
    "growthPercentage = 100.0*((finalMoney-initialMoney)/initialMoney)\n",
    "timeLenInYears = len(prices)/252.0\n",
    "\n",
    "print(\"[DEBUG] Current money:\\t   US$ \" + str(round(currentMoney, 2)))\n",
    "print(\"[DEBUG] Current stocks:\\t   \" + str(round(currentStocks, 2)) + \"\\t| Last stock-price: US$ \" + str(round(lastPrice, 2)))\n",
    "print(\"First date:\\t   \" + sorted(prices.keys())[1] + \"\\t| Initial stock value: US$ \" + firstPrice)\n",
    "print(\"Last date:\\t   \" + sorted(prices.keys())[-1] + \"\\t| Final stock value: US$ \" + lastPrice)\n",
    "print(\"Initial money:    US$ \" + str(round(initialMoney, 2)) + \" | Final money: US$ \" + str(round(finalMoney, 2)))\n",
    "print(\"Final profit:\\t   US$ \" + str(round(finalMoney-initialMoney, 2)) + \" over \" + str(round(timeLenInYears, 2)) + \" years\")\n",
    "print(\"Growth percentage: \" + str(round(growthPercentage, 2)) + \"%\")\n",
    "print(\"Growth per year:   US$ \" + str(round((finalMoney-initialMoney)/timeLenInYears, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"mlp\"][8] = MLP_8.predict(X_test[\"mlp\"][8], batch_size=batch_size)\n",
    "print(classification_report(y_test[\"mlp\"][8], np.rint(preds[\"mlp\"][8]), target_names=eight_dict.keys(), digits=5))\n",
    "conf = plot_confusion_matrix(y_test[\"mlp\"][8].argmax(axis=1), np.rint(preds[\"mlp\"][8]).argmax(axis=1), classes=np.array(list(eight_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_lstm_2 = LSTM_2.fit(X_train[\"lstm\"][2], y_train[\"lstm\"][2], epochs=200, verbose=1, validation_split=.2, batch_size=batch_size)\n",
    "plt.plot(history_lstm_2.history['loss'], label='train')\n",
    "plt.plot(history_lstm_2.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"lstm\"][2] = LSTM_2.predict(X_test[\"lstm\"][2], batch_size=batch_size)\n",
    "print(classification_report(y_test[\"lstm\"][2], np.rint(preds[\"lstm\"][2]).astype(np.int64), target_names=[\"S\",\"B\"], digits=5))\n",
    "conf = plot_confusion_matrix(y_test[\"lstm\"][2], np.rint(preds[\"lstm\"][2]).astype(np.int64), classes=np.array([\"S\",\"B\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm_8 = LSTM_8.fit(X_train[\"lstm\"][8], y_train[\"lstm\"][8], epochs=300, verbose=1, validation_split=.2, batch_size=batch_size)\n",
    "plt.plot(history_lstm_8.history['loss'], label='train')\n",
    "plt.plot(history_lstm_8.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"lstm\"][8] = LSTM_8.predict(X_test[\"lstm\"][8], batch_size=batch_size)\n",
    "print(classification_report(y_test[\"lstm\"][8], np.rint(preds[\"lstm\"][8]).astype(np.int64), target_names=eight_dict.keys(), digits=5))\n",
    "conf = plot_confusion_matrix(y_test[\"lstm\"][8].argmax(axis=1), np.rint(preds[\"lstm\"][8]).argmax(axis=1), classes=np.array(list(eight_dict.keys())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
